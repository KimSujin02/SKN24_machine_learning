{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa29bdfa",
   "metadata": {},
   "source": [
    "# 교차 검증 (Cross Validation)\n",
    "\n",
    "- 모델을 더욱 신뢰성 있게 평가하는 방법\n",
    "- 데이터셋을 여러(k) 개로 나누고, 각 부분이 한번씩 검증 데이터로 사용되도록 하는 방법\n",
    "- 훈련-검증을 반복하며 학습 진행\n",
    "- 과대적합 방지 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c18706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e1bbd",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7a1755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_input, iris_target = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5027143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([50, 50, 50]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(iris_target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43468ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c7cdce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# KFold()\n",
    "# - n_splits: 폴드 개수 (K)\n",
    "# - shuffle: 폴드로 나누기 전에 섞을건지 여부\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, eval_idx in kfold.split(iris_input):\n",
    "    X_train, y_train = iris_input[train_idx], iris_target[train_idx]\n",
    "    X_eval, y_eval = iris_input[eval_idx], iris_target[eval_idx]\n",
    "\n",
    "    # print(np.unique(y_train, return_counts=True))\n",
    "    # print(np.unique(y_eval, return_counts=True))\n",
    "    # print('==================================================')\n",
    "\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    y_pred = lr_clf.predict(X_eval)\n",
    "    # print(accuracy_score(y_eval, y_pred))\n",
    "    cv_accuracy.append(accuracy_score(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "723a6041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9733333333333334)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KFold 교차 검증에 따른 분류모델 정확도\n",
    "print(cv_accuracy)\n",
    "np.mean(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674f6a6",
   "metadata": {},
   "source": [
    "### Stratified-K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b21e636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "==================================================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "==================================================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "==================================================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "==================================================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, eval_idx in stratified_kfold.split(iris_input, iris_target):\n",
    "    X_train, y_train = iris_input[train_idx], iris_target[train_idx]\n",
    "    X_eval, y_eval = iris_input[eval_idx], iris_target[eval_idx]\n",
    "\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    print(np.unique(y_eval, return_counts=True))\n",
    "    print('==================================================')\n",
    "\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    y_pred = lr_clf.predict(X_eval)\n",
    "    cv_accuracy.append(accuracy_score(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c021f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9666666666666667, 0.9333333333333333, 1.0, 0.9333333333333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9666666666666668)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cv_accuracy)\n",
    "np.mean(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f91cf9",
   "metadata": {},
   "source": [
    "### Scikit-learn 교차검증 함수\n",
    "\n",
    "**cross_val_score & cross_validate**\n",
    "\n",
    "- 교차 검증을 통해 모델 성능을 평가하는 함수\n",
    "- 내부적으로 지정한 횟수만큼 학습/검증을 나누어 반복 처리\n",
    "\n",
    "- 공통되는 파라미터\n",
    "    - 첫 번째 인자: 학습/검증 대상 모델\n",
    "    - 두 번째 인자: feature data\n",
    "    - 세 번째 인자: label(target) data\n",
    "    - scoring 키워드 인자: 평가 지표\n",
    "    - cv 키워드 인자: 반복 횟수 (기본적으로 KFold 사용, StratifiedKFold 객체 전달 가능)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10892110",
   "metadata": {},
   "source": [
    "##### cross_val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3584ebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9733333333333334)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 반복한 훈련별 검증 점수 배열 반환\n",
    "scores = cross_val_score(lr_clf, iris_input, iris_target, scoring='accuracy', cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b302d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.9666666666666668)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StratifiedKFold 객체 사용 가능\n",
    "scores = cross_val_score(lr_clf, iris_input, iris_target, scoring='accuracy', cv=stratified_kfold)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e411db",
   "metadata": {},
   "source": [
    "##### cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "547084f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0244801 , 0.01503539, 0.01459718, 0.00850534, 0.01855779]),\n",
       " 'score_time': array([0.        , 0.        , 0.00102377, 0.        , 0.        ]),\n",
       " 'test_accuracy': array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ]),\n",
       " 'train_accuracy': array([0.96666667, 0.96666667, 0.98333333, 0.98333333, 0.975     ]),\n",
       " 'test_f1_macro': array([0.96658312, 1.        , 0.93265993, 0.96658312, 1.        ]),\n",
       " 'train_f1_macro': array([0.96664582, 0.96664582, 0.98333333, 0.98332291, 0.97499609])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# 반복한 훈련별 학습시간, 평가시간, 검증점수 반환\n",
    "cross_validate(\n",
    "    lr_clf, iris_input, iris_target,\n",
    "    scoring=['accuracy', 'f1_macro'],   # 다중 지표 사용 가능\n",
    "    cv=5,\n",
    "    return_train_score=True             # 학습 데이터에 대한 검증점수 반환 가능\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9d37d",
   "metadata": {},
   "source": [
    "### [한번 해보기] 생선 다중 분류 with cross_val_score\n",
    "\n",
    "- 생선의 Weight, Length, Diagonal, Height, Width를 사용해 생선의 Species를 예측하는 문제를 LogisticRegression 모델로 해결해 보세요.\n",
    "    - cross_val_score() 함수를 사용해 교차 검증을 적용\n",
    "    - LogisticRegression의 Hyper Parameter를 바꿔가며 테스트\n",
    "    - 최적의 성능을 내는 Hyper Parameter를 찾아보세요 ^_^@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5196b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.42000e+02, 2.54000e+01, 3.00000e+01, 1.15200e+01, 4.02000e+00],\n",
       "        [2.90000e+02, 2.63000e+01, 3.12000e+01, 1.24800e+01, 4.30560e+00],\n",
       "        [3.40000e+02, 2.65000e+01, 3.11000e+01, 1.23778e+01, 4.69610e+00],\n",
       "        [3.63000e+02, 2.90000e+01, 3.35000e+01, 1.27300e+01, 4.45550e+00],\n",
       "        [4.30000e+02, 2.90000e+01, 3.40000e+01, 1.24440e+01, 5.13400e+00],\n",
       "        [4.50000e+02, 2.97000e+01, 3.47000e+01, 1.36024e+01, 4.92740e+00],\n",
       "        [5.00000e+02, 2.97000e+01, 3.45000e+01, 1.41795e+01, 5.27850e+00],\n",
       "        [3.90000e+02, 3.00000e+01, 3.50000e+01, 1.26700e+01, 4.69000e+00],\n",
       "        [4.50000e+02, 3.00000e+01, 3.51000e+01, 1.40049e+01, 4.84380e+00],\n",
       "        [5.00000e+02, 3.07000e+01, 3.62000e+01, 1.42266e+01, 4.95940e+00],\n",
       "        [4.75000e+02, 3.10000e+01, 3.62000e+01, 1.42628e+01, 5.10420e+00],\n",
       "        [5.00000e+02, 3.10000e+01, 3.62000e+01, 1.43714e+01, 4.81460e+00],\n",
       "        [5.00000e+02, 3.15000e+01, 3.64000e+01, 1.37592e+01, 4.36800e+00],\n",
       "        [3.40000e+02, 3.20000e+01, 3.73000e+01, 1.39129e+01, 5.07280e+00],\n",
       "        [6.00000e+02, 3.20000e+01, 3.72000e+01, 1.49544e+01, 5.17080e+00],\n",
       "        [6.00000e+02, 3.20000e+01, 3.72000e+01, 1.54380e+01, 5.58000e+00],\n",
       "        [7.00000e+02, 3.30000e+01, 3.83000e+01, 1.48604e+01, 5.28540e+00],\n",
       "        [7.00000e+02, 3.30000e+01, 3.85000e+01, 1.49380e+01, 5.19750e+00],\n",
       "        [6.10000e+02, 3.35000e+01, 3.86000e+01, 1.56330e+01, 5.13380e+00],\n",
       "        [6.50000e+02, 3.35000e+01, 3.87000e+01, 1.44738e+01, 5.72760e+00],\n",
       "        [5.75000e+02, 3.40000e+01, 3.95000e+01, 1.51285e+01, 5.56950e+00],\n",
       "        [6.85000e+02, 3.40000e+01, 3.92000e+01, 1.59936e+01, 5.37040e+00],\n",
       "        [6.20000e+02, 3.45000e+01, 3.97000e+01, 1.55227e+01, 5.28010e+00],\n",
       "        [6.80000e+02, 3.50000e+01, 4.06000e+01, 1.54686e+01, 6.13060e+00],\n",
       "        [7.00000e+02, 3.50000e+01, 4.05000e+01, 1.62405e+01, 5.58900e+00],\n",
       "        [7.25000e+02, 3.50000e+01, 4.09000e+01, 1.63600e+01, 6.05320e+00],\n",
       "        [7.20000e+02, 3.50000e+01, 4.06000e+01, 1.63618e+01, 6.09000e+00],\n",
       "        [7.14000e+02, 3.60000e+01, 4.15000e+01, 1.65170e+01, 5.85150e+00],\n",
       "        [8.50000e+02, 3.60000e+01, 4.16000e+01, 1.68896e+01, 6.19840e+00],\n",
       "        [1.00000e+03, 3.70000e+01, 4.26000e+01, 1.89570e+01, 6.60300e+00],\n",
       "        [9.20000e+02, 3.85000e+01, 4.41000e+01, 1.80369e+01, 6.30630e+00],\n",
       "        [9.55000e+02, 3.85000e+01, 4.40000e+01, 1.80840e+01, 6.29200e+00],\n",
       "        [9.25000e+02, 3.95000e+01, 4.53000e+01, 1.87542e+01, 6.74970e+00],\n",
       "        [9.75000e+02, 4.10000e+01, 4.59000e+01, 1.86354e+01, 6.74730e+00],\n",
       "        [9.50000e+02, 4.10000e+01, 4.65000e+01, 1.76235e+01, 6.37050e+00],\n",
       "        [4.00000e+01, 1.41000e+01, 1.62000e+01, 4.14720e+00, 2.26800e+00],\n",
       "        [6.90000e+01, 1.82000e+01, 2.03000e+01, 5.29830e+00, 2.82170e+00],\n",
       "        [7.80000e+01, 1.88000e+01, 2.12000e+01, 5.57560e+00, 2.90440e+00],\n",
       "        [8.70000e+01, 1.98000e+01, 2.22000e+01, 5.61660e+00, 3.17460e+00],\n",
       "        [1.20000e+02, 2.00000e+01, 2.22000e+01, 6.21600e+00, 3.57420e+00],\n",
       "        [0.00000e+00, 2.05000e+01, 2.28000e+01, 6.47520e+00, 3.35160e+00],\n",
       "        [1.10000e+02, 2.08000e+01, 2.31000e+01, 6.16770e+00, 3.39570e+00],\n",
       "        [1.20000e+02, 2.10000e+01, 2.37000e+01, 6.11460e+00, 3.29430e+00],\n",
       "        [1.50000e+02, 2.20000e+01, 2.47000e+01, 5.80450e+00, 3.75440e+00],\n",
       "        [1.45000e+02, 2.20000e+01, 2.43000e+01, 6.63390e+00, 3.54780e+00],\n",
       "        [1.60000e+02, 2.25000e+01, 2.53000e+01, 7.03340e+00, 3.82030e+00],\n",
       "        [1.40000e+02, 2.25000e+01, 2.50000e+01, 6.55000e+00, 3.32500e+00],\n",
       "        [1.60000e+02, 2.25000e+01, 2.50000e+01, 6.40000e+00, 3.80000e+00],\n",
       "        [1.69000e+02, 2.40000e+01, 2.72000e+01, 7.53440e+00, 3.83520e+00],\n",
       "        [1.61000e+02, 2.34000e+01, 2.67000e+01, 6.91530e+00, 3.63120e+00],\n",
       "        [2.00000e+02, 2.35000e+01, 2.68000e+01, 7.39680e+00, 4.12720e+00],\n",
       "        [1.80000e+02, 2.52000e+01, 2.79000e+01, 7.08660e+00, 3.90600e+00],\n",
       "        [2.90000e+02, 2.60000e+01, 2.92000e+01, 8.87680e+00, 4.49680e+00],\n",
       "        [2.72000e+02, 2.70000e+01, 3.06000e+01, 8.56800e+00, 4.77360e+00],\n",
       "        [3.90000e+02, 3.17000e+01, 3.50000e+01, 9.48500e+00, 5.35500e+00],\n",
       "        [2.70000e+02, 2.60000e+01, 2.87000e+01, 8.38040e+00, 4.24760e+00],\n",
       "        [2.70000e+02, 2.65000e+01, 2.93000e+01, 8.14540e+00, 4.24850e+00],\n",
       "        [3.06000e+02, 2.80000e+01, 3.08000e+01, 8.77800e+00, 4.68160e+00],\n",
       "        [5.40000e+02, 3.10000e+01, 3.40000e+01, 1.07440e+01, 6.56200e+00],\n",
       "        [8.00000e+02, 3.64000e+01, 3.96000e+01, 1.17612e+01, 6.57360e+00],\n",
       "        [1.00000e+03, 4.00000e+01, 4.35000e+01, 1.23540e+01, 6.52500e+00],\n",
       "        [5.50000e+01, 1.47000e+01, 1.65000e+01, 6.84750e+00, 2.32650e+00],\n",
       "        [6.00000e+01, 1.55000e+01, 1.74000e+01, 6.57720e+00, 2.31420e+00],\n",
       "        [9.00000e+01, 1.77000e+01, 1.98000e+01, 7.40520e+00, 2.67300e+00],\n",
       "        [1.20000e+02, 1.90000e+01, 2.13000e+01, 8.39220e+00, 2.91810e+00],\n",
       "        [1.50000e+02, 2.00000e+01, 2.24000e+01, 8.89280e+00, 3.29280e+00],\n",
       "        [1.40000e+02, 2.07000e+01, 2.32000e+01, 8.53760e+00, 3.29440e+00],\n",
       "        [1.70000e+02, 2.07000e+01, 2.32000e+01, 9.39600e+00, 3.41040e+00],\n",
       "        [1.45000e+02, 2.15000e+01, 2.41000e+01, 9.73640e+00, 3.15710e+00],\n",
       "        [2.00000e+02, 2.30000e+01, 2.58000e+01, 1.03458e+01, 3.66360e+00],\n",
       "        [2.73000e+02, 2.50000e+01, 2.80000e+01, 1.10880e+01, 4.14400e+00],\n",
       "        [3.00000e+02, 2.60000e+01, 2.90000e+01, 1.13680e+01, 4.23400e+00],\n",
       "        [5.90000e+00, 8.40000e+00, 8.80000e+00, 2.11200e+00, 1.40800e+00],\n",
       "        [3.20000e+01, 1.37000e+01, 1.47000e+01, 3.52800e+00, 1.99920e+00],\n",
       "        [4.00000e+01, 1.50000e+01, 1.60000e+01, 3.82400e+00, 2.43200e+00],\n",
       "        [5.15000e+01, 1.62000e+01, 1.72000e+01, 4.59240e+00, 2.63160e+00],\n",
       "        [7.00000e+01, 1.74000e+01, 1.85000e+01, 4.58800e+00, 2.94150e+00],\n",
       "        [1.00000e+02, 1.80000e+01, 1.92000e+01, 5.22240e+00, 3.32160e+00],\n",
       "        [7.80000e+01, 1.87000e+01, 1.94000e+01, 5.19920e+00, 3.12340e+00],\n",
       "        [8.00000e+01, 1.90000e+01, 2.02000e+01, 5.63580e+00, 3.05020e+00],\n",
       "        [8.50000e+01, 1.96000e+01, 2.08000e+01, 5.13760e+00, 3.03680e+00],\n",
       "        [8.50000e+01, 2.00000e+01, 2.10000e+01, 5.08200e+00, 2.77200e+00],\n",
       "        [1.10000e+02, 2.10000e+01, 2.25000e+01, 5.69250e+00, 3.55500e+00],\n",
       "        [1.15000e+02, 2.10000e+01, 2.25000e+01, 5.91750e+00, 3.30750e+00],\n",
       "        [1.25000e+02, 2.10000e+01, 2.25000e+01, 5.69250e+00, 3.66750e+00],\n",
       "        [1.30000e+02, 2.13000e+01, 2.28000e+01, 6.38400e+00, 3.53400e+00],\n",
       "        [1.20000e+02, 2.20000e+01, 2.35000e+01, 6.11000e+00, 3.40750e+00],\n",
       "        [1.20000e+02, 2.20000e+01, 2.35000e+01, 5.64000e+00, 3.52500e+00],\n",
       "        [1.30000e+02, 2.20000e+01, 2.35000e+01, 6.11000e+00, 3.52500e+00],\n",
       "        [1.35000e+02, 2.20000e+01, 2.35000e+01, 5.87500e+00, 3.52500e+00],\n",
       "        [1.10000e+02, 2.20000e+01, 2.35000e+01, 5.52250e+00, 3.99500e+00],\n",
       "        [1.30000e+02, 2.25000e+01, 2.40000e+01, 5.85600e+00, 3.62400e+00],\n",
       "        [1.50000e+02, 2.25000e+01, 2.40000e+01, 6.79200e+00, 3.62400e+00],\n",
       "        [1.45000e+02, 2.27000e+01, 2.42000e+01, 5.95320e+00, 3.63000e+00],\n",
       "        [1.50000e+02, 2.30000e+01, 2.45000e+01, 5.21850e+00, 3.62600e+00],\n",
       "        [1.70000e+02, 2.35000e+01, 2.50000e+01, 6.27500e+00, 3.72500e+00],\n",
       "        [2.25000e+02, 2.40000e+01, 2.55000e+01, 7.29300e+00, 3.72300e+00],\n",
       "        [1.45000e+02, 2.40000e+01, 2.55000e+01, 6.37500e+00, 3.82500e+00],\n",
       "        [1.88000e+02, 2.46000e+01, 2.62000e+01, 6.73340e+00, 4.16580e+00],\n",
       "        [1.80000e+02, 2.50000e+01, 2.65000e+01, 6.43950e+00, 3.68350e+00],\n",
       "        [1.97000e+02, 2.56000e+01, 2.70000e+01, 6.56100e+00, 4.23900e+00],\n",
       "        [2.18000e+02, 2.65000e+01, 2.80000e+01, 7.16800e+00, 4.14400e+00],\n",
       "        [3.00000e+02, 2.73000e+01, 2.87000e+01, 8.32300e+00, 5.13730e+00],\n",
       "        [2.60000e+02, 2.75000e+01, 2.89000e+01, 7.16720e+00, 4.33500e+00],\n",
       "        [2.65000e+02, 2.75000e+01, 2.89000e+01, 7.05160e+00, 4.33500e+00],\n",
       "        [2.50000e+02, 2.75000e+01, 2.89000e+01, 7.28280e+00, 4.56620e+00],\n",
       "        [2.50000e+02, 2.80000e+01, 2.94000e+01, 7.82040e+00, 4.20420e+00],\n",
       "        [3.00000e+02, 2.87000e+01, 3.01000e+01, 7.58520e+00, 4.63540e+00],\n",
       "        [3.20000e+02, 3.00000e+01, 3.16000e+01, 7.61560e+00, 4.77160e+00],\n",
       "        [5.14000e+02, 3.28000e+01, 3.40000e+01, 1.00300e+01, 6.01800e+00],\n",
       "        [5.56000e+02, 3.45000e+01, 3.65000e+01, 1.02565e+01, 6.38750e+00],\n",
       "        [8.40000e+02, 3.50000e+01, 3.73000e+01, 1.14884e+01, 7.79570e+00],\n",
       "        [6.85000e+02, 3.65000e+01, 3.90000e+01, 1.08810e+01, 6.86400e+00],\n",
       "        [7.00000e+02, 3.60000e+01, 3.83000e+01, 1.06091e+01, 6.74080e+00],\n",
       "        [7.00000e+02, 3.70000e+01, 3.94000e+01, 1.08350e+01, 6.26460e+00],\n",
       "        [6.90000e+02, 3.70000e+01, 3.93000e+01, 1.05717e+01, 6.36660e+00],\n",
       "        [9.00000e+02, 3.90000e+01, 4.14000e+01, 1.11366e+01, 7.49340e+00],\n",
       "        [6.50000e+02, 3.90000e+01, 4.14000e+01, 1.11366e+01, 6.00300e+00],\n",
       "        [8.20000e+02, 3.90000e+01, 4.13000e+01, 1.24313e+01, 7.35140e+00],\n",
       "        [8.50000e+02, 4.00000e+01, 4.23000e+01, 1.19286e+01, 7.10640e+00],\n",
       "        [9.00000e+02, 4.00000e+01, 4.25000e+01, 1.17300e+01, 7.22500e+00],\n",
       "        [1.01500e+03, 4.00000e+01, 4.24000e+01, 1.23808e+01, 7.46240e+00],\n",
       "        [8.20000e+02, 4.00000e+01, 4.25000e+01, 1.11350e+01, 6.63000e+00],\n",
       "        [1.10000e+03, 4.20000e+01, 4.46000e+01, 1.28002e+01, 6.86840e+00],\n",
       "        [1.00000e+03, 4.30000e+01, 4.52000e+01, 1.19328e+01, 7.27720e+00],\n",
       "        [1.10000e+03, 4.30000e+01, 4.55000e+01, 1.25125e+01, 7.41650e+00],\n",
       "        [1.00000e+03, 4.35000e+01, 4.60000e+01, 1.26040e+01, 8.14200e+00],\n",
       "        [1.00000e+03, 4.40000e+01, 4.66000e+01, 1.24888e+01, 7.59580e+00],\n",
       "        [2.00000e+02, 3.23000e+01, 3.48000e+01, 5.56800e+00, 3.37560e+00],\n",
       "        [3.00000e+02, 3.40000e+01, 3.78000e+01, 5.70780e+00, 4.15800e+00],\n",
       "        [3.00000e+02, 3.50000e+01, 3.88000e+01, 5.93640e+00, 4.38440e+00],\n",
       "        [3.00000e+02, 3.73000e+01, 3.98000e+01, 6.28840e+00, 4.01980e+00],\n",
       "        [4.30000e+02, 3.80000e+01, 4.05000e+01, 7.29000e+00, 4.57650e+00],\n",
       "        [3.45000e+02, 3.85000e+01, 4.10000e+01, 6.39600e+00, 3.97700e+00],\n",
       "        [4.56000e+02, 4.25000e+01, 4.55000e+01, 7.28000e+00, 4.32250e+00],\n",
       "        [5.10000e+02, 4.25000e+01, 4.55000e+01, 6.82500e+00, 4.45900e+00],\n",
       "        [5.40000e+02, 4.30000e+01, 4.58000e+01, 7.78600e+00, 5.12960e+00],\n",
       "        [5.00000e+02, 4.50000e+01, 4.80000e+01, 6.96000e+00, 4.89600e+00],\n",
       "        [5.67000e+02, 4.60000e+01, 4.87000e+01, 7.79200e+00, 4.87000e+00],\n",
       "        [7.70000e+02, 4.80000e+01, 5.12000e+01, 7.68000e+00, 5.37600e+00],\n",
       "        [9.50000e+02, 5.17000e+01, 5.51000e+01, 8.92620e+00, 6.17120e+00],\n",
       "        [1.25000e+03, 5.60000e+01, 5.97000e+01, 1.06863e+01, 6.98490e+00],\n",
       "        [1.60000e+03, 6.00000e+01, 6.40000e+01, 9.60000e+00, 6.14400e+00],\n",
       "        [1.55000e+03, 6.00000e+01, 6.40000e+01, 9.60000e+00, 6.14400e+00],\n",
       "        [1.65000e+03, 6.34000e+01, 6.80000e+01, 1.08120e+01, 7.48000e+00],\n",
       "        [6.70000e+00, 9.80000e+00, 1.08000e+01, 1.73880e+00, 1.04760e+00],\n",
       "        [7.50000e+00, 1.05000e+01, 1.16000e+01, 1.97200e+00, 1.16000e+00],\n",
       "        [7.00000e+00, 1.06000e+01, 1.16000e+01, 1.72840e+00, 1.14840e+00],\n",
       "        [9.70000e+00, 1.10000e+01, 1.20000e+01, 2.19600e+00, 1.38000e+00],\n",
       "        [9.80000e+00, 1.12000e+01, 1.24000e+01, 2.08320e+00, 1.27720e+00],\n",
       "        [8.70000e+00, 1.13000e+01, 1.26000e+01, 1.97820e+00, 1.28520e+00],\n",
       "        [1.00000e+01, 1.18000e+01, 1.31000e+01, 2.21390e+00, 1.28380e+00],\n",
       "        [9.90000e+00, 1.18000e+01, 1.31000e+01, 2.21390e+00, 1.16590e+00],\n",
       "        [9.80000e+00, 1.20000e+01, 1.32000e+01, 2.20440e+00, 1.14840e+00],\n",
       "        [1.22000e+01, 1.22000e+01, 1.34000e+01, 2.09040e+00, 1.39360e+00],\n",
       "        [1.34000e+01, 1.24000e+01, 1.35000e+01, 2.43000e+00, 1.26900e+00],\n",
       "        [1.22000e+01, 1.30000e+01, 1.38000e+01, 2.27700e+00, 1.25580e+00],\n",
       "        [1.97000e+01, 1.43000e+01, 1.52000e+01, 2.87280e+00, 2.06720e+00],\n",
       "        [1.99000e+01, 1.50000e+01, 1.62000e+01, 2.93220e+00, 1.87920e+00]]),\n",
       " array(['Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "        'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "        'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "        'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "        'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream', 'Bream',\n",
       "        'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach',\n",
       "        'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach',\n",
       "        'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Roach', 'Whitefish',\n",
       "        'Whitefish', 'Whitefish', 'Whitefish', 'Whitefish', 'Whitefish',\n",
       "        'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Parkki',\n",
       "        'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Parkki', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch',\n",
       "        'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Pike', 'Pike',\n",
       "        'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike',\n",
       "        'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Pike', 'Smelt',\n",
       "        'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt',\n",
       "        'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt'], dtype=object))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "fish = pd.read_csv('./data/fish.csv')\n",
    "\n",
    "# 특성 데이터(Weight, Length, Diagonal, Height, Width)와 타깃 데이터(Species) 분리\n",
    "fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "\n",
    "fish_input, fish_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1def7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습-평가 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    fish_input, fish_target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41bb627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_input)\n",
    "\n",
    "train_scaled = scaler.transform(train_input)\n",
    "test_scaled = scaler.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d17e1864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 교차 검증 정확도: 0.7864615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\miniconda3\\envs\\mlstudy_env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:813: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성(하이퍼 파라미터 조작) 및 교차검증\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 교차 검증 수행 (cv=5)\n",
    "scores = cross_val_score(lr_clf, train_scaled, train_target, cv=5)\n",
    "\n",
    "print(f\"평균 교차 검증 정확도: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 학습 세트 점수: 0.9921\n",
      "최종 테스트 세트 점수: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터에 대한 추론 결과 평가\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, eval_idx in stratified_kfold.split(iris_input, iris_target):\n",
    "    X_train, y_train = iris_input[train_idx], iris_target[train_idx]\n",
    "    X_eval, y_eval = iris_input[eval_idx], iris_target[eval_idx]\n",
    "\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    print(np.unique(y_eval, return_counts=True))\n",
    "    print('==================================================')\n",
    "\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    y_pred = lr_clf.predict(X_eval)\n",
    "    cv_accuracy.append(accuracy_score(y_eval, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlstudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
