{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b1cbc2",
   "metadata": {},
   "source": [
    "# 앙상블 (Ensemble) : Boosting\n",
    "\n",
    "- 깊이가 앝은 결정트리를 사용해 이전 트리의 오차를 보정하는 방식\n",
    "- 순차적으로 경사하강법을 사용해 이전 트리의 오차를 줄여나감\n",
    "    - 분류 모델에서는 손실함수 Logloss를 사용해 오차를 줄임\n",
    "    - 회귀 모델에서는 손실함수 MSE를 사용해 오차를 줄임\n",
    "- Boosting 계열은 일반적으로 결정트리 개수를 늘려도 과적합에 강함\n",
    "- 대표적인 Boosting 알고리즘(모델) : GradientBoosting, HistGradientBoosting, XGBoost(DMLC), LightGBM(MS), CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb82ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a863f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.initial_prediction = 0     # 초기 예측값\n",
    "        self.trees = []                 # estimators 모음 배열\n",
    "    \n",
    "    def log_odds(self, p):\n",
    "        return np.log(p / (1 - p))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_mean = np.mean(y)\n",
    "        self.initial_log_adds = self.log_odds(y_mean)\n",
    "        y_pred_log_odds = np.full(y.shape[0], self.initial_log_adds, dtype=np.float64)\n",
    "        \n",
    "        # 개별 모델 생성 및 학습\n",
    "        for _ in range(self.n_estimators):\n",
    "            # 현재 상태에서의 예측 확률 계산\n",
    "            y_pred_proba = self.sigmoid(y_pred_log_odds)\n",
    "            \n",
    "            # 잔차(손실) 계산\n",
    "            residuals = y - y_pred_proba\n",
    "            \n",
    "            # 결정 트리 생성 -> 잔차를 라벨로 해서 학습\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "            # 예측값 업데이트 (예측값 점진적 개선)\n",
    "            y_pred_log_odds += self.learning_rate * tree.predict(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_pred_log_odds = np.full(X.shape[0], self.initial_log_adds)\n",
    "        \n",
    "        for tree in self.trees:\n",
    "            y_pred_log_odds += self.learning_rate * tree.predict(X)\n",
    "        \n",
    "        return self.sigmoid(y_pred_log_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6944594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 정확도 : 0.9929577464788732\n",
      "평가 정확도 : 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bc_ds = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(bc_ds.data, bc_ds.target, random_state=0)\n",
    "\n",
    "simple_gb_clf = SimpleGradientBoostingClassifier()\n",
    "simple_gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = simple_gb_clf.predict(X_train)\n",
    "y_pred_test = simple_gb_clf.predict(X_test)\n",
    "\n",
    "print(f\"학습 정확도 : {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"평가 정확도 : {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1ae1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 정확도 : 1.0\n",
      "평가 정확도 : 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = gb_clf.predict(X_train)\n",
    "y_pred_test = gb_clf.predict(X_test)\n",
    "print(f\"학습 정확도 : {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"평가 정확도 : {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddda22d",
   "metadata": {},
   "source": [
    "### HistGradientBoosting\n",
    "\n",
    "- 고성능 GradientBoosting 모델로 대규모 데이터셋 처리에 적합\n",
    "- Histpgram 기반으로 256개의 구간으로 나누어 처리 병합하는 방식\n",
    "- 결측치가 있어도 전처리가 필요 없음\n",
    "- LightGBM 영향을 받아 만들어진 scikit-learn의 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc41ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 정확도 : 1.0\n",
      "평가 정확도 : 0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hist_gb_clf = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    max_bins=255,           # 255개의 구간으로 나누어 처리(1개는 결측치 전용)\n",
    "    early_stopping=True,    # 학습 반복 중 '일정 횟수' 이상 성능 향상이 없으면 중단\n",
    "    n_iter_no_change=5      # early_stopping이 True일 때, 성능 향상이 없다고 판단할 '일정 횟수' (기본값 : 10)\n",
    ")\n",
    "hist_gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = hist_gb_clf.predict(X_train)\n",
    "y_pred_test = hist_gb_clf.predict(X_test)\n",
    "print(f\"학습 정확도 : {accuracy_score(y_train, y_pred_train)}\")\n",
    "print(f\"평가 정확도 : {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4631988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'importances_mean': array([0.        , 0.00187793, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01032864, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00093897, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01267606, 0.02253521, 0.00187793, 0.        ,\n",
       "        0.        , 0.        , 0.00187793, 0.        , 0.        ]),\n",
       " 'importances_std': array([0.        , 0.00175665, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0028169 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00115   , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00115   , 0.00435381, 0.00175665, 0.        ,\n",
       "        0.        , 0.        , 0.00093897, 0.        , 0.        ]),\n",
       " 'importances': array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.00234742, 0.        , 0.00234742, 0.00469484],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.01408451, 0.01173709, 0.01173709, 0.00704225, 0.00704225],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.00234742, 0.        , 0.00234742],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.01173709, 0.01408451, 0.01173709, 0.01408451, 0.01173709],\n",
       "        [0.03051643, 0.02347418, 0.01877934, 0.01877934, 0.02112676],\n",
       "        [0.00234742, 0.        , 0.        , 0.00234742, 0.00469484],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.00234742, 0.00234742, 0.00234742, 0.        , 0.00234742],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    hist_gb_clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_repeats=5,            # 실험을 다섯번 하겠다는 뜻\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "result.importances_mean     # feature별 중요도 평균\n",
    "result.importances_std      # 중요도의 표준편차\n",
    "result.importances          # 중요도 (n_features, n_repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57676f",
   "metadata": {},
   "source": [
    "### GradientBoosting [Regression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d097a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "db_ds = load_diabetes()\n",
    "\n",
    "db_df = pd.DataFrame(db_ds.data, columns=db_ds.feature_names)\n",
    "db_df['target'] = db_ds.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    db_ds.data,\n",
    "    db_ds.target,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f323185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 MSE : 2348.383005252592\n",
      "평가 MSE : 2723.2143923397316\n",
      "학습 R2 : 0.6114923312793334\n",
      "평가 R2 : 0.5075285428540747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "hist_gb_reg = HistGradientBoostingRegressor(\n",
    "    max_iter=200,\n",
    "    max_depth=1,\n",
    "    learning_rate=0.1,\n",
    "    random_state=0,\n",
    "    l2_regularization=0.0,\n",
    "    min_samples_leaf=20,\n",
    "    max_bins=127\n",
    ")\n",
    "\n",
    "hist_gb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = hist_gb_reg.predict(X_train)\n",
    "y_pred_test = hist_gb_reg.predict(X_test)\n",
    "\n",
    "print(f\"학습 MSE : {mean_squared_error(y_train, y_pred_train)}\")\n",
    "print(f\"평가 MSE : {mean_squared_error(y_test, y_pred_test)}\")\n",
    "print(f\"학습 R2 : {r2_score(y_train, y_pred_train)}\")\n",
    "print(f\"평가 R2 : {r2_score(y_test, y_pred_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlstudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
